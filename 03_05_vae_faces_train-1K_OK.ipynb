{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Training - Faces dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "#GPU tuning\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from models.VAE_a import VariationalAutoencoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run/vae/0001_faces\n",
      "data/CelebA/celeba_1k\n"
     ]
    }
   ],
   "source": [
    "# run params\n",
    "section = 'vae'\n",
    "run_id = '0001'\n",
    "data_name = 'faces'\n",
    "RUN_FOLDER = 'run/{}/'.format(section)\n",
    "RUN_FOLDER += '_'.join([run_id, data_name])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'load' #\n",
    "\n",
    "DATA_FOLDER_0 = 'data/CelebA/'\n",
    "DATA_FOLDER = os.path.join(DATA_FOLDER_0, 'celeba_1k') \n",
    "\n",
    "print(RUN_FOLDER)\n",
    "print(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "962"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM = (128,128,3)\n",
    "BATCH_SIZE = 50\n",
    "EPOCHS = 20\n",
    "\n",
    "filenames = np.array(glob(os.path.join(DATA_FOLDER, '*/*.jpg')))\n",
    "\n",
    "NUM_IMAGES = len(filenames)\n",
    "NUM_IMAGES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move 12 files to: data/CelebA/move_dir\n",
      "Proceed? (0 - NO)1\n",
      "move files - done\n"
     ]
    }
   ],
   "source": [
    "# Dataset check \n",
    "move_flag = False \n",
    "\n",
    "if NUM_IMAGES % BATCH_SIZE !=0:\n",
    "    print(\"WARNING: Dataset size not match with EPOCHS! extra:\",  NUM_IMAGES % BATCH_SIZE )\n",
    "    move_flag = True\n",
    "    move_files = filenames[-(NUM_IMAGES % BATCH_SIZE):]       \n",
    "else:\n",
    "    print(\"Dataset OK\")\n",
    "    move_flag = False \n",
    "\n",
    "# Move extra files from Dataset\n",
    "    \n",
    "if move_flag:\n",
    "    move_dir = os.path.join(DATA_FOLDER_0, 'move_dir')\n",
    "    print(\"Move {:d} files to: {:s}\".format(len(move_files), move_dir))\n",
    "    ask = input(\"Proceed? (0 - NO)_\")\n",
    "    if ask != '0':\n",
    "        if not os.path.exists(move_dir):\n",
    "            os.mkdir(move_dir)\n",
    "        for f in move_files:\n",
    "            #print(f, os.path.join(move_dir, f.split('\\\\')[-1]))\n",
    "            shutil.move(f, os.path.join(move_dir, f.split('\\\\')[-1]))\n",
    "        print(\"move files - done\")\n",
    "    else:\n",
    "        print(\"canceled\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = np.array(glob(os.path.join(DATA_FOLDER, '*/*.jpg')))\n",
    "\n",
    "NUM_IMAGES = len(filenames)\n",
    "NUM_IMAGES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 950 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "data_flow = data_gen.flow_from_directory(DATA_FOLDER\n",
    "                                         , target_size = INPUT_DIM[:2]\n",
    "                                         , batch_size = BATCH_SIZE\n",
    "                                         , shuffle = True\n",
    "                                         , class_mode = 'input'\n",
    "                                         , subset = \"training\"\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1215 23:49:08.228910  6728 util.py:150] Unresolved object in checkpoint: (root).optimizer\n",
      "W1215 23:49:08.228910  6728 util.py:150] Unresolved object in checkpoint: (root).loss\n",
      "W1215 23:49:08.228910  6728 util.py:158] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "vae = VariationalAutoencoder(\n",
    "                input_dim = INPUT_DIM\n",
    "                , encoder_conv_filters=[32,64,64, 64]\n",
    "                , encoder_conv_kernel_size=[3,3,3,3]\n",
    "                , encoder_conv_strides=[2,2,2,2]\n",
    "                , decoder_conv_t_filters=[64,64,32,3]\n",
    "                , decoder_conv_t_kernel_size=[3,3,3,3]\n",
    "                , decoder_conv_t_strides=[2,2,2,2]\n",
    "                , z_dim=200\n",
    "                , use_batch_norm=True\n",
    "                , use_dropout=True\n",
    "                , r_loss_factor = 10000\n",
    "                )\n",
    "\n",
    "if mode == 'build':\n",
    "    vae.save(RUN_FOLDER)\n",
    "else:\n",
    "    vae.load_weights(os.path.join(RUN_FOLDER, 'weights/weights_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)         (None, 64, 64, 32)   896         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 64, 32)   128         encoder_conv_0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 64, 64, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 64, 64, 32)   0           leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)         (None, 32, 32, 64)   18496       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 64)   256         encoder_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 32, 32, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 32, 32, 64)   0           leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)         (None, 16, 16, 64)   36928       dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 64)   256         encoder_conv_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 16, 16, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 64)   0           leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)         (None, 8, 8, 64)     36928       dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 64)     256         encoder_conv_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 8, 8, 64)     0           leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 4096)         0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 200)          819400      flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_var (Dense)                 (None, 200)          819400      flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Sampling)       (None, 200)          0           mu[0][0]                         \n",
      "                                                                 log_var[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,732,944\n",
      "Trainable params: 1,732,496\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              823296    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_0 (Conv2DTran (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_1 (Conv2DTran (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_2 (Conv2DTran (None, 64, 64, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_3 (Conv2DTran (None, 128, 128, 3)       867       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 917,123\n",
      "Trainable params: 916,803\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "INITIAL_EPOCH = 0 \n",
    "EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = NUM_IMAGES / BATCH_SIZE\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 405.3929 - reconstruction_loss: 341.7052 - kl_loss: 63.6877\n",
      "Epoch 00001: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 122ms/step - loss: 406.3905 - reconstruction_loss: 342.6037 - kl_loss: 63.7867\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 401.9257 - reconstruction_loss: 337.8846 - kl_loss: 64.0411\n",
      "Epoch 00002: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 118ms/step - loss: 401.6696 - reconstruction_loss: 337.6788 - kl_loss: 63.9908\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 397.4433 - reconstruction_loss: 332.7776 - kl_loss: 64.6656\n",
      "Epoch 00003: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 121ms/step - loss: 398.1548 - reconstruction_loss: 333.5357 - kl_loss: 64.6191\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 395.1759 - reconstruction_loss: 328.5284 - kl_loss: 66.6475\n",
      "Epoch 00004: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 117ms/step - loss: 395.3744 - reconstruction_loss: 328.4898 - kl_loss: 66.8846\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 390.5764 - reconstruction_loss: 324.2218 - kl_loss: 66.3546\n",
      "Epoch 00005: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 123ms/step - loss: 390.1150 - reconstruction_loss: 323.7744 - kl_loss: 66.3406\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 391.2389 - reconstruction_loss: 323.4345 - kl_loss: 67.8044\n",
      "Epoch 00006: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 121ms/step - loss: 391.6129 - reconstruction_loss: 323.7793 - kl_loss: 67.8335\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 386.7510 - reconstruction_loss: 318.9686 - kl_loss: 67.7824\n",
      "Epoch 00007: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 118ms/step - loss: 386.7632 - reconstruction_loss: 318.8729 - kl_loss: 67.8903\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 382.6902 - reconstruction_loss: 314.8278 - kl_loss: 67.8623\n",
      "Epoch 00008: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 120ms/step - loss: 383.8680 - reconstruction_loss: 316.3468 - kl_loss: 67.5212\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 379.4849 - reconstruction_loss: 311.3806 - kl_loss: 68.1043\n",
      "Epoch 00009: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 122ms/step - loss: 380.5897 - reconstruction_loss: 312.5453 - kl_loss: 68.0444\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 375.4823 - reconstruction_loss: 306.1836 - kl_loss: 69.2987\n",
      "Epoch 00010: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 117ms/step - loss: 375.2916 - reconstruction_loss: 305.9567 - kl_loss: 69.3349\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 373.4481 - reconstruction_loss: 304.6624 - kl_loss: 68.7858\n",
      "Epoch 00011: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 124ms/step - loss: 373.1461 - reconstruction_loss: 304.1656 - kl_loss: 68.9805\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 371.2740 - reconstruction_loss: 301.7135 - kl_loss: 69.5604\n",
      "Epoch 00012: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 121ms/step - loss: 370.9599 - reconstruction_loss: 301.5475 - kl_loss: 69.4124\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 365.6252 - reconstruction_loss: 296.1632 - kl_loss: 69.4621\n",
      "Epoch 00013: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 118ms/step - loss: 366.5166 - reconstruction_loss: 297.0285 - kl_loss: 69.4881\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 362.5386 - reconstruction_loss: 292.1214 - kl_loss: 70.4172\n",
      "Epoch 00014: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 120ms/step - loss: 361.6536 - reconstruction_loss: 291.2171 - kl_loss: 70.4366\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 356.0032 - reconstruction_loss: 284.6035 - kl_loss: 71.3997\n",
      "Epoch 00015: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 120ms/step - loss: 355.6476 - reconstruction_loss: 284.4989 - kl_loss: 71.1487\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 351.2468 - reconstruction_loss: 280.1942 - kl_loss: 71.0525\n",
      "Epoch 00016: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 120ms/step - loss: 350.5900 - reconstruction_loss: 279.4956 - kl_loss: 71.0944\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 346.5181 - reconstruction_loss: 275.4118 - kl_loss: 71.1063\n",
      "Epoch 00017: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 121ms/step - loss: 347.2332 - reconstruction_loss: 276.2128 - kl_loss: 71.0204\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 343.7886 - reconstruction_loss: 271.4767 - kl_loss: 72.3120\n",
      "Epoch 00018: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 121ms/step - loss: 343.6759 - reconstruction_loss: 271.2541 - kl_loss: 72.4218\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 341.2685 - reconstruction_loss: 269.4376 - kl_loss: 71.8309\n",
      "Epoch 00019: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 120ms/step - loss: 341.3873 - reconstruction_loss: 269.2896 - kl_loss: 72.0977\n",
      "Epoch 20/20\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 337.5723 - reconstruction_loss: 265.9376 - kl_loss: 71.6346\n",
      "Epoch 00020: saving model to run/vae/0001_faces\\weights\\weights-20.ckpt\n",
      "19/19 [==============================] - ETA: 0s - loss: 337.4359 - reconstruction_loss: 265.9243 - kl_loss: 71.5115\n",
      "Epoch 00020: saving model to run/vae/0001_faces\\weights\\weights\n",
      "19/19 [==============================] - 2s 123ms/step - loss: 337.3131 - reconstruction_loss: 265.9124 - kl_loss: 71.4007\n"
     ]
    }
   ],
   "source": [
    "vae.train_with_generator(     \n",
    "    data_flow\n",
    "    , epochs = EPOCHS\n",
    "    , steps_per_epoch = NUM_IMAGES / BATCH_SIZE\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , save_every_n_batches = 20\n",
    "    , initial_epoch = INITIAL_EPOCH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run/vae/0001_faces\\\\weights/weights_2.data-00000-of-00001'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#copy weghts\n",
    "suff = '.data-00000-of-00001'\n",
    "\n",
    "shutil.copy(os.path.join(RUN_FOLDER, 'weights/weights'+ suff), os.path.join(RUN_FOLDER, 'weights/weights_' + suff))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
