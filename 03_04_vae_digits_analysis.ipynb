{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "#GPU tuning\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import norm\n",
    "\n",
    "from models.VAE import VariationalAutoencoder\n",
    "from utils.loaders import load_mnist, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'vae'\n",
    "RUN_ID = '0002'\n",
    "DATA_NAME = 'digits'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2ab977dbe975>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariationalAutoencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRUN_FOLDER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\_ML\\GenDeepLearn_C\\GDL_code2\\utils\\loaders.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(model_class, folder)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights/weights.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\_ML\\GenDeepLearn_C\\GDL_code2\\models\\VAE.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every_n_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_decay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\toolkits\\anaconda3\\envs\\gen_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2198\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2199\u001b[0m       raise ValueError(\n\u001b[1;32m-> 2200\u001b[1;33m           \u001b[1;34m'Unable to load weights saved in HDF5 format into a subclassed '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2201\u001b[0m           \u001b[1;34m'Model which has not created its variables yet. Call the Model '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2202\u001b[0m           'first, then load the weights.')\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights."
     ]
    }
   ],
   "source": [
    "vae = load_model(VariationalAutoencoder, RUN_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reconstructing original paintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_show = 10\n",
    "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
    "example_images = x_test[example_idx]\n",
    "\n",
    "_,_,z_points = vae.encoder.predict(example_images)\n",
    "\n",
    "reconst_images = vae.decoder.predict(z_points)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(n_to_show):\n",
    "    img = example_images[i].squeeze()\n",
    "    sub = fig.add_subplot(2, n_to_show, i+1)\n",
    "    sub.axis('off')\n",
    "    sub.text(0.5, -0.35, str(np.round(z_points[i],1)), fontsize=10, ha='center', transform=sub.transAxes)\n",
    "            \n",
    "    sub.imshow(img, cmap='gray_r')\n",
    "\n",
    "for i in range(n_to_show):\n",
    "    img = reconst_images[i].squeeze()\n",
    "    sub = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n",
    "    sub.axis('off')\n",
    "    sub.imshow(img, cmap='gray_r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mr N. Coder's wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_show = 5000\n",
    "figsize = 12\n",
    "\n",
    "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
    "example_images = x_test[example_idx]\n",
    "example_labels = y_test[example_idx]\n",
    "\n",
    "_,_,z_points = vae.encoder.predict(example_images)\n",
    "\n",
    "min_x = min(z_points[:, 0])\n",
    "max_x = max(z_points[:, 0])\n",
    "min_y = min(z_points[:, 1])\n",
    "max_y = max(z_points[:, 1])\n",
    "\n",
    "plt.figure(figsize=(figsize, figsize))\n",
    "plt.scatter(z_points[:, 0] , z_points[:, 1], c='black', alpha=0.5, s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The new generated art exhibition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = 8\n",
    "plt.figure(figsize=(figsize, figsize))\n",
    "plt.scatter(z_points[:, 0] , z_points[:, 1], c='black', alpha=0.5, s=2)\n",
    "\n",
    "\n",
    "grid_size = 15\n",
    "grid_depth = 2\n",
    "figsize = 15\n",
    "\n",
    "x = np.random.normal(size = grid_size * grid_depth)\n",
    "y = np.random.normal(size = grid_size * grid_depth)\n",
    "\n",
    "z_grid = np.array(list(zip(x, y)))\n",
    "reconst = vae.decoder.predict(z_grid)\n",
    "\n",
    "plt.scatter(z_grid[:, 0] , z_grid[:, 1], c = 'red', alpha=1, s=20)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(figsize, grid_depth))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(grid_size*grid_depth):\n",
    "    ax = fig.add_subplot(grid_depth, grid_size, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, str(np.round(z_grid[i],1)), fontsize=8, ha='center', transform=ax.transAxes)\n",
    "    \n",
    "    ax.imshow(reconst[i, :,:,0], cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_show = 5000\n",
    "grid_size = 15\n",
    "fig_height = 7\n",
    "fig_width = 15\n",
    "\n",
    "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
    "example_images = x_test[example_idx]\n",
    "example_labels = y_test[example_idx]\n",
    "\n",
    "_,_,z_points = vae.encoder.predict(example_images)\n",
    "p_points = norm.cdf(z_points)\n",
    "\n",
    "fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plot_1 = ax.scatter(z_points[:, 0] , z_points[:, 1] , cmap='rainbow' , c= example_labels\n",
    "            , alpha=0.5, s=2)\n",
    "plt.colorbar(plot_1)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plot_2 = ax.scatter(p_points[:, 0] , p_points[:, 1] , cmap='rainbow' , c= example_labels\n",
    "            , alpha=0.5, s=5)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_show = 5000\n",
    "grid_size = 20\n",
    "figsize = 8\n",
    "\n",
    "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
    "example_images = x_test[example_idx]\n",
    "example_labels = y_test[example_idx]\n",
    "\n",
    "_,_,z_points = vae.encoder.predict(example_images)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(z_points[:, 0] , z_points[:, 1] , cmap='rainbow' , c= example_labels\n",
    "            , alpha=0.5, s=2)\n",
    "plt.colorbar()\n",
    "\n",
    "x = norm.ppf(np.linspace(0.01, 0.99, grid_size))\n",
    "y = norm.ppf(np.linspace(0.01, 0.99, grid_size))\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "xv = xv.flatten()\n",
    "yv = yv.flatten()\n",
    "z_grid = np.array(list(zip(xv, yv)))\n",
    "\n",
    "reconst = vae.decoder.predict(z_grid)\n",
    "\n",
    "plt.scatter(z_grid[:, 0] , z_grid[:, 1], c = 'black'#, cmap='rainbow' , c= example_labels\n",
    "            , alpha=1, s=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(figsize, figsize))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "for i in range(grid_size**2):\n",
    "    ax = fig.add_subplot(grid_size, grid_size, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.imshow(reconst[i, :,:,0], cmap = 'Greys')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
